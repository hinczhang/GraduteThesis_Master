{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59edf917-a44c-417b-b62e-bc3cb6d154c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './EX/spatial.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 读取 CSV 文件\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_EX \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./EX/spatial.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, skip_blank_lines\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m df_CO \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./CO/spatial.csv\u001b[39m\u001b[39m\"\u001b[39m, skip_blank_lines\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# 找到空行的索引\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './EX/spatial.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# 读取 CSV 文件\n",
    "df_EX = pd.read_csv(\"./EX/spatial.csv\", skip_blank_lines=False)\n",
    "df_CO = pd.read_csv(\"./CO/spatial.csv\", skip_blank_lines=False)\n",
    "\n",
    "# 找到空行的索引\n",
    "blank_line_indices_ex = df_EX.index[df_EX.isnull().all(1)]\n",
    "blank_line_indices_co = df_CO.index[df_CO.isnull().all(1)]\n",
    "\n",
    "# 初始化三个空的 DataFrame\n",
    "dataframes_ex = []\n",
    "start_idx_ex = 0\n",
    "\n",
    "dataframes_co = []\n",
    "start_idx_co = 0\n",
    "\n",
    "\n",
    "# 根据空行的索引将数据分割成三个 DataFrame\n",
    "for idx in blank_line_indices_ex:\n",
    "    dataframes_ex.append(df_EX.iloc[start_idx_ex:idx])\n",
    "    start_idx_ex = idx + 1\n",
    "\n",
    "for idx in blank_line_indices_co:\n",
    "    dataframes_co.append(df_CO.iloc[start_idx_co:idx])\n",
    "    start_idx_co = idx + 1\n",
    "    \n",
    "# 处理最后一个部分（如果有剩余的数据）\n",
    "if start_idx_ex < len(df_EX):\n",
    "    dataframes_ex.append(df_EX.iloc[start_idx_ex:])\n",
    "if start_idx_co < len(df_CO):\n",
    "    dataframes_co.append(df_CO.iloc[start_idx_co:])\n",
    "print(len(dataframes_ex))\n",
    "print(len(dataframes_co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bbd8f-c75b-4548-ae68-c0f04dac6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATS for experiment units: \")\n",
    "for idx, df in enumerate(dataframes_ex):\n",
    "    # 根据 \"type\" 列进行分组\n",
    "    df[\"TYPE\"].astype(int)\n",
    "    df[\"TYPE\"].astype(str)\n",
    "\n",
    "    grouped = df.groupby(\"TYPE\")\n",
    "    \n",
    "    # 提取列名为 \"1~12\" 的列\n",
    "    columns_to_average = [str(i) for i in range(1, 15)]\n",
    "\n",
    "    # 计算每个分组中 \"1~12\" 列的平均值\n",
    "    averages = grouped[columns_to_average].mean().mean(axis=1)\n",
    "    print(\"BLOCK \", idx + 1)\n",
    "    print(averages)\n",
    "columns_to_average = [str(i) for i in range(1, 15)]\n",
    "merged_df_ex = pd.concat(dataframes_ex, ignore_index=True)\n",
    "grouped_ex = merged_df_ex.groupby(\"TYPE\")\n",
    "avg_frame_ex = grouped_ex[columns_to_average].mean()\n",
    "avg_ex = avg_frame_ex.mean(axis=1)\n",
    "print(\"Overall avg: \")\n",
    "print(avg_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50aa782-bfaf-49ad-a676-6bf6d65a588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATS for control units: \")\n",
    "for idx, df in enumerate(dataframes_co):\n",
    "    # 根据 \"type\" 列进行分组\n",
    "    df[\"TYPE\"] = df[\"TYPE\"].astype(int)\n",
    "    df[\"TYPE\"] = df[\"TYPE\"].astype(str)\n",
    "    grouped = df.groupby(\"TYPE\")\n",
    "    # 提取列名为 \"1~12\" 的列\n",
    "    columns_to_average = [str(i) for i in range(1, 18)]\n",
    "    print(\"BLOCK \", idx + 1)\n",
    "    # 计算每个分组中 \"1~12\" 列的平均值\n",
    "    averages = grouped[columns_to_average].mean().mean(axis=1)\n",
    "    print(averages)\n",
    "columns_to_average = [str(i) for i in range(1, 18)]\n",
    "merged_df_co = pd.concat(dataframes_co, ignore_index=True)\n",
    "grouped_co = merged_df_co.groupby(\"TYPE\")\n",
    "avg_frame_co = grouped_co[columns_to_average].mean()\n",
    "avg_co = avg_frame_co.mean(axis=1)\n",
    "print(\"Overall avg: \")\n",
    "print(avg_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73afc6a-2dbb-4a66-acd4-b726ca32ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_frame_ex.index = avg_frame_ex.index.map(lambda x: str(int(x)) + \"_EX\")\n",
    "avg_frame_co.index = avg_frame_co.index.map(lambda x: str(int(x)) + \"_CO\")\n",
    "avg_frame_ex = avg_frame_ex.T\n",
    "avg_frame_co = avg_frame_co.T\n",
    "\n",
    "# 绘制箱线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 绘制 frame1 的箱线图\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_frame_ex.boxplot()\n",
    "plt.ylim(0, 1.3)\n",
    "plt.title(\"Experiment group\")\n",
    "\n",
    "# 绘制 frame2 的箱线图\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_frame_co.boxplot()\n",
    "plt.ylim(0, 1.3)\n",
    "plt.title(\"Control group\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5745d-a2e5-492f-9381-a968b16350fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import levene, bartlett\n",
    "\n",
    "# 假设你有多个样本组，存储在 sample1, sample2, sample3 等数组中\n",
    "\n",
    "# 进行方差齐性检验\n",
    "# 使用 Levene's test\n",
    "levene_test_statistic, levene_p_value = levene(avg_frame_co[\"0_CO\"].tolist(), avg_frame_ex[\"0_EX\"].tolist())\n",
    "\n",
    "# 使用 Bartlett's test\n",
    "bartlett_test_statistic, bartlett_p_value = bartlett(avg_frame_co[\"0_CO\"].tolist(), avg_frame_ex[\"0_EX\"].tolist())\n",
    "\n",
    "# 打印检验结果\n",
    "print(\"Levene's Test:\")\n",
    "print(f\"Test Statistic: {levene_test_statistic}\")\n",
    "print(f\"P-value: {levene_p_value}\")\n",
    "print()\n",
    "\n",
    "print(\"Bartlett's Test:\")\n",
    "print(f\"Test Statistic: {bartlett_test_statistic}\")\n",
    "print(f\"P-value: {bartlett_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3424481-4767-493f-adcd-f405ed9cdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import levene, bartlett\n",
    "\n",
    "# 假设你有多个样本组，存储在 sample1, sample2, sample3 等数组中\n",
    "\n",
    "# 进行方差齐性检验\n",
    "# 使用 Levene's test\n",
    "levene_test_statistic, levene_p_value = levene(avg_frame_co[\"1_CO\"].tolist(), avg_frame_ex[\"1_EX\"].tolist())\n",
    "\n",
    "# 使用 Bartlett's test\n",
    "bartlett_test_statistic, bartlett_p_value = bartlett(avg_frame_co[\"1_CO\"].tolist(), avg_frame_ex[\"1_EX\"].tolist())\n",
    "\n",
    "# 打印检验结果\n",
    "print(\"Levene's Test:\")\n",
    "print(f\"Test Statistic: {levene_test_statistic}\")\n",
    "print(f\"P-value: {levene_p_value}\")\n",
    "print()\n",
    "\n",
    "print(\"Bartlett's Test:\")\n",
    "print(f\"Test Statistic: {bartlett_test_statistic}\")\n",
    "print(f\"P-value: {bartlett_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce1c00-5991-42fe-b830-3fbc710dc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# 假设你有两个独立的样本组，存储在 sample1 和 sample2 中\n",
    "\n",
    "# 执行独立样本 t 检验\n",
    "t_statistic, p_value = ttest_ind(avg_frame_co[\"0_CO\"].tolist(), avg_frame_ex[\"0_EX\"].tolist())\n",
    "\n",
    "# 打印检验结果\n",
    "print(\"Independent Samples t-test:\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# 根据 P 值判断是否存在显著差异\n",
    "alpha = 0.05  # 显著性水平\n",
    "if p_value < alpha:\n",
    "    print(\"存在显著差异\")\n",
    "else:\n",
    "    print(\"不存在显著差异\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794fecd-735d-4339-89a4-ac6c96f84daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# 假设你有两个独立的样本组，存储在 sample1 和 sample2 中\n",
    "\n",
    "# 执行 Mann-Whitney U 检验\n",
    "statistic, p_value = mannwhitneyu(avg_frame_co[\"1_CO\"].tolist(), avg_frame_ex[\"1_EX\"].tolist(), alternative='two-sided')\n",
    "\n",
    "# 打印检验结果\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(f\"Test Statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# 根据 P 值判断是否存在显著差异\n",
    "alpha = 0.05  # 显著性水平\n",
    "if p_value < alpha:\n",
    "    print(\"存在显著差异\")\n",
    "else:\n",
    "    print(\"不存在显著差异\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a180468-0c0b-4dd3-a809-32071e2cdbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
